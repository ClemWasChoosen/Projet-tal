<add>
  <doc>
    <field name="category">technology</field>
    <field name="headline">La démocratie qui utilise la reconnaissance faciale pour enregistrer les visages de ses citoyens</field>
    <field name="text">Si une personne de l'État d'Australie occidentale contracte le covid-19, elle doit rester en quarantaine à domicile pendant les sept jours suivants, tout comme ses contacts proches. La police vérifie leur localisation en envoyant périodiquement des SMS et exige l'envoi d'un selfie dans les 15 minutes. La technologie de reconnaissance faciale et le suivi GPS sont utilisés pour déterminer si la personne qui a pris le selfie est effectivement chez elle.\n\nSi cela n'est pas fait, la police frappe rapidement à votre porte avec une amende potentiellement lourde. L'application G2G, créée par la start-up technologique locale Genvis, a été utilisée par plus de 150 000 personnes dans l'État depuis son lancement en septembre 2020. La même technologie, fournie par des entreprises différentes, a été testée dans les États de Nouvelle-Galles du Sud, de Victoria, d'Australie-Méridionale et de Tasmanie. L'Australie se distingue comme la seule démocratie à utiliser la technologie de reconnaissance faciale pour aider aux mesures de confinement du covid-19, alors que d'autres pays rejettent ce type de surveillance. Amazon, Microsoft, IBM et Google ont déclaré qu'ils ne vendraient pas leurs algorithmes de reconnaissance faciale aux organismes chargés de l'application de la loi tant qu'une loi fédérale ne serait pas en vigueur.\n\nEn novembre 2021, Meta a annoncé que Facebook allait supprimer 1 milliard d'"identités faciales" d'utilisateurs et cesser d'utiliser cette technologie pour marquer les personnes sur les photos.\n\nLa Commission australienne des droits de l'homme a demandé un moratoire sur l'utilisation de cette technologie jusqu'à ce que le pays dispose d'une loi spécifique pour réglementer son utilisation.\n\nLes défenseurs des droits humains affirment que les données personnelles obtenues peuvent être utilisées à des fins secondaires et qu'il s'agit là d'un moyen de devenir un État de surveillance.\n\nDes groupes tels qu'Amnesty International mettent également en garde contre le fait que l'utilisation de la reconnaissance faciale entraîne une discrimination raciale.\n\n"La pandémie a créé toutes ces nouvelles justifications pour l'utilisation de la technologie de reconnaissance faciale", explique Mark Andrejevic, professeur d'études des médias à l'université Monash de Melbourne et auteur d'un livre à paraître, Facial Recognition.\n\n"Tout a été mis en ligne et les organisations ont essayé de faire fonctionner les choses très rapidement. Mais on n'a pas pensé aux implications. Voulons-nous vivre dans un monde où tout est numérisé et où il n'y a plus d'espaces privés ? Cela crée un tout nouveau niveau de stress qui ne conduit pas à une société saine." Le consentement est requis pour l'utilisation de l'application G2G. Il a également été nécessaire après les feux de brousse de l'été 2020 en Australie, lorsque les personnes ayant perdu leurs documents d'identité ont utilisé la reconnaissance faciale pour recevoir une aide financière du gouvernement.\n\nMais il est arrivé que la technologie de reconnaissance faciale soit utilisée de manière voilée.\n\nEn octobre, le groupe de magasins de proximité 7-Eleven a été reconnu coupable d'avoir violé la vie privée de ses consommateurs en collectant les identifiants faciaux de 1,6 million de clients australiens lorsqu'ils remplissaient des enquêtes de satisfaction.\n\nLes identifications faciales auraient été utilisée afin d'obtenir des profils démographiques du public et d'empêcher les employés de manipuler les enquêtes pour augmenter leur cote. La société n'a pas été condamnée à une amende.\n\nLe ministère australien de l'Intérieur a commencé à constituer une base de données nationale de reconnaissance faciale en 2016 - et semble prêt à la mettre en œuvre. En janvier, elle a lancé un appel d'offres pour trouver une entreprise chargée de "construire et déployer" les données.\n\n"La reconnaissance faciale est sur le point d'être déployée à une échelle relativement large", déclare Andrejevic.\n\n"L'Australie se prépare à utiliser la reconnaissance faciale pour permettre l'accès aux services gouvernementaux. Et parmi les agences de sécurité publique, il y a définitivement un désir d'avoir accès à ces outils."\n\nLa plupart des gouvernements des États ont fourni les permis de conduire de leurs résidents à la base de données centrale, qui stocke également les photos des visas et des passeports.\n\nEn 2019, un projet de loi a été proposé pour réglementer la technologie de reconnaissance faciale - mis au placard après qu'un examen par une commission parlementaire ait constaté qu'elle n'offrait pas de protections adéquates de la vie privée.\n\nParmi ses plus fervents détracteurs figurait le commissaire australien aux droits de l'homme de l'époque, Edward Santow. "Nous sommes maintenant dans la pire des situations, puisqu'il n'y a pas de loi spécifique, nous avons affaire à des protections fragmentaires qui ne sont pas complètement efficaces et certainement pas complètes", dit Santow.\n\n"Mais la technologie continue d'être déployée".\n\nM. Santow travaille avec son équipe de l'Université de technologie de Sydney sur les moyens de rendre les dispositions relatives à la vie privée plus solides. Une partie du projet consiste à examiner les tentatives d'autres pays de réglementer les technologies de reconnaissance faciale.\n\nIl existe des approches totalement différentes dans le monde. La plus courante consiste à s'appuyer sur une poignée de protections limitées de la vie privée qui, selon M. Santow, ne permettent pas de résoudre le problème de manière adéquate, comme c'est le cas en Australie.\n\n"Aucun pays au monde n'a réussi à le faire", dit-il.\n\n"Si [les protections de la vie privée étaient adéquates], ce projet serait vraiment simple".\n\nLeila Nashashibi est une militante du groupe Fight for the Future, basé aux États-Unis, qui milite pour une interdiction fédérale de la reconnaissance faciale et d'autres formes d'identifiants biométriques.\n\n"À l'instar de l'énergie nucléaire et des armes biologiques, la reconnaissance faciale représente une menace pour la société humaine et nos libertés fondamentales qui dépasse de loin tous les avantages potentiels", prévient-il.\n\n"La reconnaissance faciale ne ressemble à aucune autre forme de surveillance, car elle permet un contrôle automatisé et omniprésent de populations entières, et peut être presque impossible à empêcher. À mesure qu'il se répand, les gens auront trop peur de participer à des mouvements sociaux et à des manifestations politiques. La liberté d'expression va être refroidie". Le fournisseur le plus connu de la technologie de reconnaissance faciale, la société américaine Clearview AI, ne semble pas découragé par les procès et les lourdes amendes qu'il accumule dans diverses juridictions.\n\nLa technologie de la société a d'abord attiré l'attention de la presse lorsqu'un milliardaire l'a utilisée pour identifier la personne avec laquelle sa fille allait dîner. Elle est actuellement utilisée par le gouvernement ukrainien pour identifier les soldats russes morts.\n\nLes familles des victimes sont prévenues via les médias sociaux, les photos étant parfois envoyées en pièce jointe.\n\nL'entreprise tente également de faire utiliser sa technologie dans les écoles américaines en tant que "système de gestion des visiteurs", qui, selon elle, pourrait contribuer à prévenir les fusillades en reconnaissant les visages des étudiants expulsés, par exemple.\n\nLa technologie de reconnaissance faciale a déjà été testée dans plusieurs écoles par différents fournisseurs, tout comme la technologie de reconnaissance d'objets, qui serait capable d'identifier une arme dissimulée.\n\n"Clearview AI exploite la terreur et le traumatisme des gens en disant que la surveillance et le maintien de l'ordre sont la réponse", évalue Nashashibi. Hoan Ton-That, fondateur et PDG australien de Clearview AI, n'est pas d'accord.\n\nSelon lui, la technologie de reconnaissance faciale présente un grand potentiel pour la prévention de la criminalité, car elle permet de s'assurer que seules les personnes autorisées ont accès à un bâtiment tel qu'une école.\n\n"Nous avons vu notre technologie utilisée avec beaucoup de succès par les forces de l'ordre pour mettre fin au trafic d'armes, et nous espérons que notre technologie pourra être utilisée pour aider à prévenir les crimes tragiques liés aux armes à feu à l'avenir", dit-il.\n\nEn Australie, la technologie de reconnaissance faciale est utilisée dans plusieurs stades pour empêcher l'entrée de terroristes présumés ou de hooligans du football qui ont été contrôlés.\n\nM. Andrejevic estime que l'utilisation de la reconnaissance faciale comme mesure de sécurité constitue une avancée significative en matière de surveillance et doit être examinée avec soin.\n\n"On reproche souvent à la vidéosurveillance (réseau de caméras de surveillance) de n'offrir des preuves qu'après coup, alors que la reconnaissance faciale génère des informations utiles en temps réel pour prévenir la criminalité", explique-t-il.\n\n"C'est une conception très différente de la sécurité".\n\nLa reconnaissance faciale en temps réel est déjà utilisée par certaines forces de police dans le monde.\n\nLa police métropolitaine de Londres, par exemple, l'utilise pour surveiller des zones spécifiques à la recherche de criminels ou de personnes susceptibles de représenter un risque pour le public. Clearview a créé une base de données de 20 milliards d'images faciales, en grande partie en saisissant des photos sur les médias sociaux sans consentement.\n\nTon-That affirme que l'entreprise ne travaillera pas avec des gouvernements autoritaires comme ceux de la Chine, de la Corée du Nord et de l'Iran. Mais elle a rencontré des problèmes dans certaines démocraties.\n\nIl a été interdit au Canada et en Australie et, le 24 mai, l'Information Commissioner's Office (ICO) du Royaume-Uni lui a infligé une amende de plus de 7,5 millions de livres sterling après une enquête conjointe avec l'organisme australien correspondant.\n\nLa société a reçu l'ordre de supprimer les données des résidents britanniques de ses systèmes.\n\nEn décembre 2021, l'organisme français de surveillance de la vie privée a estimé que Clearview avait enfreint le Règlement général sur la protection des données (RGPD) de l'Europe.\n\nSelon M. Santow, l'objectif en Australie est de développer une approche différenciée qui encourage l'utilisation d'applications positives et impose des protections pour prévenir les dommages.\n\nLe pire scénario serait de reproduire le système chinois de "crédit social", dans lequel les individus et les organisations sont sélectionnés par le gouvernement pour déterminer leur "fiabilité".\n\n"Pour déterminer si une utilisation est bénéfique ou nuisible, nous nous référons au cadre international de base des droits de l'homme qui existe dans presque toutes les juridictions du monde", explique M. Santow.\n\nPar exemple, la loi exigerait un consentement libre et éclairé pour utiliser la reconnaissance faciale.\n\nToutefois, si la technologie était source de discrimination en raison de son inexactitude par rapport à certains groupes, le consentement ne serait plus pertinent. Comme le dit Santow :\n\n"Vous ne pouvez pas consentir à être victime de disc "Au cours des deux prochaines années, nous allons assister à un changement radical dans l'utilisation des mots de passe, qui ne sont absolument pas sûrs. La biométrie va devenir la norme", affirme M. O'Hara.\n\nLa reconnaissance faciale fonctionne en divisant le visage en une série de formes géométriques et en cartographiant les distances entre leurs "points de repère", tels que le nez, les yeux et la bouche.\n\nCes distances sont comparées à celles d'autres visages et transformées en un code unique appelé marqueur biométrique.\n\n"Lorsque vous utilisez une application de reconnaissance faciale pour ouvrir votre téléphone, ce n'est pas une photo de votre visage que votre téléphone stocke", explique Garrett O'Hara, responsable de la sécurité chez la société de sécurité Mimecast.\n\n"Il stocke une dérivation algorithmique de ce que votre visage est mathématiquement. Ça ressemble à un long code de lettres et de chiffres."\n\nLa reconnaissance faciale a parcouru un long chemin depuis sa mise au point dans les années 1960, même si le taux d'erreur varie considérablement entre les différents systèmes utilisés aujourd'hui.\n\nAu début, il était incapable de distinguer les frères et sœurs ou les changements dans le visage d'une personne au fur et à mesure de son vieillissement.\n\nAujourd'hui, il est si sophistiqué qu'il peut identifier une personne portant un masque ou des lunettes noires, et ce à plus d'un kilomètre de distance.\n\nLe meilleur algorithme d'identification des visages a un taux d'erreur de seulement 0,08 %, selon des tests effectués par le National Institute of Standards and Technology des États-Unis.\n\nToutefois, ce niveau de précision n'est possible que dans des conditions idéales, où les traits du visage sont clairs et non masqués, où l'éclairage est bon et où la personne fait face à la caméra.\n\nLe taux d'erreur pour les individus capturés au hasard peut atteindre 9,3 %.\n\n"C'est une technologie incroyablement utile. Mais si quelqu'un nous avait demandé il y a 20 ans, lorsque l'internet mondial n'en était qu'à ses débuts, si nous voulions vivre dans un monde où nos interactions et nos activités seraient collectées et suivies, la plupart d'entre nous auraient probablement répondu que cela semblait effrayant", note M. O'Hara.\n\n"Maintenant, nous reproduisons le suivi de l'espace en ligne pour inclure l'espace physique également. Et nous ne posons pas les questions que nous devrions poser."\n\nL'un des aspects les plus problématiques est le potentiel de discrimination et de préjugés raciaux.\n\nLa plupart des applications de reconnaissance faciale ont été initialement formées à l'aide d'ensembles de données qui ne représentaient pas toute l'étendue de la communauté.\n\n"Au début, les ensembles de données utilisés étaient tous des hommes blancs ou des personnes blanches en général", explique O'Hara.\n\n"Et cela conduit clairement à des problèmes lorsque vous avez des personnes non blanches ou des personnes d'ethnies ou de milieux différents qui ne correspondent pas aux modèles de formation. Au bout du compte, ce ne sont que des mathématiques. C'est ça le problème." En conséquence, les systèmes de reconnaissance faciale sont susceptibles de commettre des erreurs lorsqu'ils tentent de reconnaître les personnes appartenant à une minorité ethnique, les femmes, les personnes handicapées et les personnes âgées.\n\nLeur utilisation a entraîné des arrestations par erreur et d'autres conséquences qui perturbent la vie des gens, rappelle M. Nashashibi. Qu'il s'agisse d'une empreinte digitale, d'un scan de l'iris, d'une analyse de la démarche ou d'un scan capillaire, aucune forme de biométrie n'est infaillible.\n\nPlus la technologie devient sophistiquée, plus les pirates tentent de la manipuler à leur profit.\n\nLes Deepfakes sont apparus comme une évolution des techniques de fraude, notamment en ce qui concerne la reconnaissance faciale numérique (c'est-à-dire les photos).\n\n"Il fallait auparavant plusieurs heures pour créer un deepfake à l'aide d'outils d'animation - aujourd'hui, cela prend quelques minutes", explique Francesco Cavalli, cofondateur de Sensity AI à Amsterdam.\n\n"Il suffit d'une photo pour créer un deepfake en 3D. Cela signifie que les fraudeurs peuvent étendre leurs opérations, et les attaques montent en flèche. Vous n'avez même pas besoin d'être un développeur ou un ingénieur. Vous pouvez le faire vous-même. Il y a des tonnes d'applications qui vous permettent de reproduire le visage de n'importe qui."\n\nSensity AI aide les gouvernements, les institutions financières et même les sites de rencontre à identifier les applications frauduleuses, qu'il s'agisse d'obtenir des paiements d'aide liés au covid-19, de stocker de l'argent blanchi sur un compte bancaire ou de faire chanter quelqu'un sur Tinder.\n\nUn test infrarouge vérifie la température du corps et le clignement des yeux lorsque quelqu'un prend une photo en ligne, ce qui signifie que la photo d'une personne "synthétique" sera détectée.\n\n"À un moment donné, les fraudeurs comprennent comment tromper nos différents modèles, et nous devons donc développer continuellement de nouvelles techniques", dit-il.\n\nMalgré les défis à relever sur la voie de la réglementation, M. Santow est optimiste et pense que l'Australie peut devenir un leader mondial en matière de réglementation de la reconnaissance faciale.\n\n"Je ne peux pas parler pour les gouvernements fédéral et d'État. Mais je sais qu'ils comprennent qu'il existe de fortes préoccupations au sein de la communauté et qu'il est nécessaire d'instaurer la confiance dans la technologie."\n\n"L'Australie peut constituer un bon modèle pour un certain nombre de raisons", ajoute-t-il.\n\n"Nous avons un fort respect institutionnel et corporatif pour les droits de l'homme. Elle n'est peut-être pas parfaite, mais elle est fondamentale pour ce que nous sommes en tant que pays. Nous sommes également un développeur et un utilisateur sophistiqué de la technologie."\n\n"Je me rends compte que le plus grand défi n'est pas d'élaborer une loi infaillible, mais de faire en sorte que la loi elle-même ne soit pas ignorée."</field>
    <field name="url">https://www.bbc.com/afrique/articles/cg65n97420eo</field>
  </doc>
</add>
